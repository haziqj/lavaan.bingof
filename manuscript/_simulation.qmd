---
execute:
  echo: false
  message: false
  warning: false
html-table-processing: none
lightbox: true
bibliography: 
  - refs-HJ.bib
---

```{r}
library(tidyverse)
library(gt)
theme_set(theme_bw())

here::i_am("manuscript/_simulation.qmd")
load(here::here("experiments/tables_figures.RData"))
```


### Simulation setup

- Describe the two models: growth curve and two-factor model
- Outcomes of interest: bias, RMSE, coverage

### Results

For the growth curve model, virtually no convergence issues.
In the two factor SEM, convergence issues in small sample sizes ($n\leq 20$) in the low reliability setting [WHY??], with as much as 30% failure and had to be removed from the analysis.

The implicit and explicit bias reduction methods took only a few seconds to run, even for the largest sample sizes. 
This offers a significant advantage over the resampling methods.

<!-- - Trim outliers (upper and lower 2.5%) -->

### Growth Curve Model

```{r}
#| label: fig-growth-medbias
#| fig-cap: 'Median bias relative to truth for various simulation scenarios in the growth curve model.'
#| out-width: 100%
fig3
```

The results highlight several notable patterns regarding the performance of bias reduction methods under varying conditions of sample size, reliability, and data distribution.
Residual variances ($\theta_{1,1}$) displayed negligible bias across all methods, sample sizes, and data distributions, consistent with the findings reported by @dhaene2022resampling.
Factor variances estimated using Maximum Likelihood (ML) showed substantial underestimation for small to moderate sample sizes. 
In general, all bias reduction methods were able to correct this issue, including both our proposed explicit and implicit bias reduction methods (eRBM and iRBM, respectively).
The factor covariance ($\theta_{1,2}$) also sees consistent bias reduction across methods, but smaller sample sizes and non-normal data lead to noticeable variability, particularly for implicit bias correction methods.
As expected, all methods converged toward expected bias values, demonstrating improved accuracy as sample size increased.

In high-reliability settings (Rel = 0.8), both eRBM and iRBM effectively reduced median bias for variance parameters, particularly for smaller sample sizes ($n\leq 50$), compared to ML estimation. 
Among the methods, iRBM outperformed all others, while eRBM showed similar performance to other sampling-based methods and the Ozenne method. 
This pattern persisted across different data distributions but changed in the presence of non-normal data, where iRBM appeared sensitive to deviations from normality. 
Low-reliability (Rel = 0.5) settings further impacted median bias, causing iRBM and all other methods to struggle in maintaining unbiasedness.


```{r}
#| label: fig-growth-perf
#| fig-cap: 'Performance of bias-corrected estimators in small sample sizes ($n=50$) for the growth curve model.'
#| out-width: 100%
fig_growth_perf
```


Mean bias analysis revealed a different pattern. 
iRBM exhibited larger mean bias, suggesting that it produced more outliers, pulling the mean estimate away from the truth.
In contrast, eRBM showed negligible mean bias, providing more stable estimates. 
This was further reflected in the RMSE results, where iRBM showed higher values, and thus higher variability of estimates around the true values, compared to ML and eRBM. 

Coverage rates were most accurate in normal data scenarios under both reliability settings, where iRBM achieved nominal coverage rates for all parameters. 
However, in more challenging conditions, particularly non-normal data, the corrective methods did not show significant improvement over ML. 
Simulation-based methods performed better in achieving accurate coverage under these conditions.

<!-- Overall, while both explicit and implicit methods showed strengths, eRBM demonstrated more consistent performance in reducing mean bias and RMSE, whereas iRBM excelled in median bias reduction but was more sensitive to outliers and non-normal data.  -->

### Two-Factor Model

```{r}
#| label: fig-twofac-medbias
#| fig-cap: 'Median bias relative to truth for various simulation scenarios in the two-factor model.'
#| out-width: 100%
#| fig-height: 5.5
fig6
```


The phenomenon of maximum likelihood (ML) underestimating variance components persist in the two-factor model, with additionally the latent regression coefficient suffering from downward bias especially in non-normal, low reliability small sample scenarios.
On the other hand, factor loadings don't seem to suffer from a lot of bias, so not interesting to compare.

For relative median bias, the iRBM demonstrated notable improvements over ML in estimating factor variances ($\Psi_{2,2}$ and $\Psi_{2,2}$) and the latent regression coefficient ($\beta$), although low reliability and non-normality impacted performance somewhat. 
In these scenarios, iRBM outperformed eRBM  but exhibited higher sensitivity to deviations in normality, with increased variability under non-normal data distributions. 
In fact, Under low reliability settings (Rel = 0.5), all methods showed increased bias, with the exception of the Ozenne method which maintained consistent performance across all conditions.


```{r}
#| label: fig-twofac-perf
#| fig-cap: 'Performance of bias-corrected estimators in small sample sizes ($n=50$) for the two-factor model.'
#| out-width: 100%
fig_twofac_perf
```

Relative mean bias results show a pattern of positive bias for the iRBM method, with the bias being as severe as 5-15% in some cases, especially in the small sample setting.
In contrast, eRBM did not show positive bias, but instead improvement in fixing the underestimation of the ML method.
Similar to the results of the previous growth curve model, it seems the iRBM method produces more outlier estimates, which pull the mean estimate upwards.
On the bright side, the residual variance $\theta$ and coefficient $\beta$ benefitted most from the iRBM method, even if the iRBM struggles to maintain unbiasedness for the factor variances.

Coverage results for 95% confidence intervals revealed strong performance by eRBM and iRBM under normal data conditions, with both methods achieving nominal coverage rates for most parameters. 
However, under non-normal data, coverage rates for iRBM and eRBM showed limited improvement over ML.
As for the RMSE, not much to be said as variability of all methods seem to be on par with each other.

### EXTRA RESULTS TO PUT IN APPENDIX

#### Growth Curve Model

```{r}
#| label: fig-growth-dis
#| fig-cap: 'Distribution of bias values (relative to truth) for various estimation methods under small sample size ($n=50$).'
#| fig-width: 8
#| fig-height: 5
#| out-width: 100%
fig_growth_dis
```


```{r}
#| label: fig-growth-meanbias
#| fig-cap: Mean bias
#| out-width: 100%
fig4
```


```{r}
#| label: fig-growth-rmse
#| fig-cap: RMSE relative to ML
fig5
```



```{r}
#| tbl-cap: 'Results (trimmed) for the growth curve model simulations (Reliability = 0.80)'
tab2
```


```{r}
#| tbl-cap: 'Results (trimmed) for the growth curve model simulations (Reliability = 0.50)'
tab3
```



```{r}
#| tbl-cap: 'Coverage'
tab4
```


#### Two-Factor Model

```{r}
#| fig-width: 8
#| fig-height: 5
#| out-width: 100%
fig_twofac_dis
```

```{r}
fig7
```

```{r}
fig8
```

```{r}
tab5
```

```{r}
tab6
```

```{r}
tab7
```

